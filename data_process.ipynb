{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07fef3dd-ca49-42f0-8a5b-8379a040dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from datasets import DatasetDict, load_dataset, load_from_disk\n",
    "from datasets.combine import concatenate_datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, TimesformerForVideoClassification\n",
    "\n",
    "FRAMES_PER_VIDEO = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a3afe7-d7ff-4ebd-a4a8-6701cb46f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k600\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "756e57a7-47b4-4e3f-b9f8-4eabf3d10d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"dataset/processed/8frames_pt1\")\n",
    "ds_train, ds_val = dataset[\"train\"], dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24ca42f4-380a-482b-994b-27ef44b88103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 110), (2, 373), (3, 90), (4, 18), (5, 6), (6, 2), (7, 1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kinetics600 classes\n",
    "actions = set(model.config.id2label.values())\n",
    "\n",
    "lengths = {}\n",
    "for action in actions:\n",
    "    length = len(action.split(\" \"))\n",
    "    if length in lengths:\n",
    "        lengths[length] += 1\n",
    "    else:\n",
    "        lengths[length] = 1\n",
    "sorted(lengths.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a62fe00-f80b-4657-b18a-6f8936eb858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6, 40, 41, 66, 67, 105, 118, 136, 185, 188, 193, 194, 195, 196, 197, 230, 252, 259, 262, 263, 271, 332, 338, 354, 357, 358, 393, 444, 463, 496, 519, 566, 589, 611, 631, 633, 654, 707, 709, 714, 731, 781, 782, 908, 926, 946, 947, 948, 949, 950, 1010, 1012, 1013, 1014, 1015, 1028, 1031, 1066, 1069, 1078, 1080, 1087, 1088, 1091, 1103, 1104, 1145, 1171, 1173, 1226, 1230, 1231, 1250, 1304, 1348, 1399, 1433, 1440, 1483, 1525, 1526, 1529, 1657, 1674, 1675, 1727, 1736, 1737, 1762, 1802, 1882, 1926, 1927, 1930, 1931, 1932, 1933, 1934, 1994, 2021, 2032, 2081, 2082, 2085, 2086, 2098, 2100, 2102, 2107, 2120, 2123, 2125, 2129, 2180, 2193, 2196, 2198, 2262, 2316, 2317, 2341, 2347, 2507, 2512, 2533, 2536, 2571, 2590, 2592, 2594, 2597, 2600, 2609, 2618, 2632, 2635, 2637, "
     ]
    }
   ],
   "source": [
    "# val idxs\n",
    "for idx in idxs:\n",
    "    print(idx, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75330a97-9ccd-45e8-a240-872e2c9e161e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A baby sitting in a high-chair, bangs her hand on the table then grabs a receipt out of a persons hand and starts laughing loudly.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ds_train[231][\"labels\"]\n",
    "tokenizer.decode(tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145d06b-b928-4661-8034-7751ecd4e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    video_id = example[\"videoID\"]\n",
    "    captions = example[\"enCap\"]\n",
    "    \n",
    "    videos_path = \"dataset/videos\"\n",
    "    video_path = os.path.join(videos_path, \"%s.mp4\" % video_id)\n",
    "    if not os.path.isfile(video_path):\n",
    "        video_path = os.path.join(videos_path, \"%s.webm\" % video_id)\n",
    "    \n",
    "    # count number of frames\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, _ = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "    video.release()\n",
    "        \n",
    "    # fixed frame sampling\n",
    "    indices = np.linspace(0, frame_count, num=FRAMES_PER_VIDEO, endpoint=False).astype(np.int64)\n",
    "    # random frame sampling\n",
    "    #indices = np.sort(np.random.uniform(low=0, high=frame_count, size=self.num_frames).astype(np.int64))\n",
    "    \n",
    "    # get frames\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_count, frame_idx = 0, 0\n",
    "    while frame_idx < len(indices):\n",
    "        if frame_count == indices[frame_idx]:\n",
    "            _, frame = video.read()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            frame_idx += 1\n",
    "        else:\n",
    "            video.grab()\n",
    "        frame_count += 1\n",
    "    video.release()\n",
    "        \n",
    "    # longest caption\n",
    "    max_len = -np.inf\n",
    "    caption = None\n",
    "    for cap in captions:\n",
    "        length = len(cap.split(\" \"))\n",
    "        if length > max_len:\n",
    "            max_len = length\n",
    "            caption = cap\n",
    "    # random caption\n",
    "    #caption = captions[random.randint(0, 9)]\n",
    "\n",
    "    labels = tokenizer(caption, padding=\"max_length\").input_ids\n",
    "    return {\"pixel_values\": frames, \"labels\": labels}\n",
    "    \n",
    "    # pixel_values = image_processor(frames, return_tensors=\"pt\").pixel_values\n",
    "    # labels = tokenizer(caption, padding=\"max_length\").input_ids\n",
    "    # return {\"pixel_values\": pixel_values[0], \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364cc2f7-5c8b-432d-9fc4-4bb8e0d9097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-dc0812067ce11954\n",
      "Found cached dataset json (/home/922201615/.cache/huggingface/datasets/json/default-dc0812067ce11954/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e536671c5b62499388fd91425676cfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['videoID', 'enCap', 'chCap'],\n",
       "        num_rows: 22895\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['videoID', 'enCap', 'chCap'],\n",
       "        num_rows: 2643\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json data\n",
    "data_files = {\"train\": \"dataset/vatex_train_captions.json\", \"validation\": \"dataset/vatex_val_captions.json\"}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "dataset\n",
    "\n",
    "# dataset[\"train\"] = dataset[\"train\"].select(np.arange(6))\n",
    "# dataset[\"validation\"] = dataset[\"validation\"].select(np.arange(3))\n",
    "\n",
    "# dataset = dataset.map(function=preprocess, remove_columns=[\"enCap\", \"chCap\"])\n",
    "# dataset.save_to_disk(\"dataset/raw_frames_16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
