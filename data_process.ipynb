{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fef3dd-ca49-42f0-8a5b-8379a040dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import json\n",
    "import os\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dade51f7-b66e-4ca8-ad12-d9e1762b8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store vatex json files as {\"videoID\" : [captions sorted by word count]}\n",
    "\n",
    "data_path = \"dataset\"\n",
    "for filename in (\"vatex_train_captions\", \"vatex_val_captions\"):\n",
    "    output = {}\n",
    "    with open(os.path.join(data_path, \"%s.json\" % filename)) as file:\n",
    "        data = json.load(file)\n",
    "        for item in data:\n",
    "            video_id, captions = item[\"videoID\"], item[\"enCap\"]\n",
    "            captions.sort(reverse=True, key=lambda cap: len(cap.split()))\n",
    "            output[video_id] = captions\n",
    "            \n",
    "    output = json.dumps(output)\n",
    "    with open(os.path.join(data_path, \"%s_videoID_keys.json\" % filename), \"w\") as file:\n",
    "        file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c9bcad-d8b9-4e65-bdbe-b73ee4177170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e150b6-3c2a-4965-86a5-dee69867c86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['videoID', 'pixel_values', 'labels'],\n",
       "        num_rows: 1016\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['videoID', 'pixel_values', 'labels'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk(\"dataset/processed/k600\")\n",
    "dataset.set_format(\"torch\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a75e3b-7892-452f-bb5a-b0a1649f2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_data, out_data = {}, {}\n",
    "with open(\"dataset/train_videoID_captions.json\") as file:\n",
    "    captions_data.update(json.load(file))\n",
    "with open(\"dataset/val_videoID_captions.json\") as file:\n",
    "    captions_data.update(json.load(file))\n",
    "\n",
    "def process(video_id, frames_per_video=8):\n",
    "    caption = captions_data[video_id][0]\n",
    "    \n",
    "    out_data[caption] = video_id\n",
    "    \n",
    "    videos_path = \"dataset/videos\"\n",
    "    video_path = os.path.join(videos_path, \"%s.mp4\" % video_id)\n",
    "    if not os.path.isfile(video_path):\n",
    "        video_path = os.path.join(videos_path, \"%s.webm\" % video_id)\n",
    "        \n",
    "    container = av.open(video_path)\n",
    "    \n",
    "    # discrepancy between in codec metadata, manually get frame count\n",
    "    container.seek(0)\n",
    "    frame_count = 0\n",
    "    for frame in container.decode(video=0):\n",
    "        frame_count += 1\n",
    "    \n",
    "    indices = set(np.linspace(0, frame_count, num=frames_per_video, endpoint=False).astype(np.int64))\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i in indices:\n",
    "            frames.append(frame.to_ndarray(format=\"rgb24\"))\n",
    "            \n",
    "    pixel_values = image_processor(frames).pixel_values\n",
    "    labels = tokenizer(caption, padding=\"max_length\").input_ids\n",
    "    return (pixel_values[0], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66e70d1-1faa-40d0-a48d-5d1c8e0c2355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n",
      "mmco: unref short failure\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d7c5289a84424bb130d70fb177dbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/20 shards):   0%|          | 0/1016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defef379692e4dadbdfacd6782ed534b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'pixel_values', 'labels'],\n",
       "        num_rows: 1016\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'pixel_values', 'labels'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = {\"video_id\": [], \"pixel_values\": [], \"labels\": []}\n",
    "for item in dataset[\"train\"]:\n",
    "    video_id = item[\"videoID\"]\n",
    "    pixel_values, labels = process(video_id, 16)\n",
    "    train_data[\"video_id\"].append(video_id)\n",
    "    train_data[\"pixel_values\"].append(pixel_values)\n",
    "    train_data[\"labels\"].append(labels)\n",
    "    \n",
    "val_data = {\"video_id\": [], \"pixel_values\": [], \"labels\": []}\n",
    "for item in dataset[\"validation\"]:\n",
    "    video_id = item[\"videoID\"]\n",
    "    pixel_values, labels = process(video_id)\n",
    "    val_data[\"video_id\"].append(video_id)\n",
    "    val_data[\"pixel_values\"].append(pixel_values)\n",
    "    val_data[\"labels\"].append(labels)\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"validation\": val_dataset})\n",
    "dataset.save_to_disk(\"dataset/processed/k600_16frames\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6102ef4-9334-4524-a5a9-31cec0c9fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/videoID_captions.json\", \"w\") as file:\n",
    "    file.write(json.dumps(captions_data))\n",
    "    \n",
    "with open(\"dataset/longestCaption_videoID.json\", \"w\") as file:\n",
    "    file.write(json.dumps(out_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
