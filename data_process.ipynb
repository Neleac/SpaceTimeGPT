{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07fef3dd-ca49-42f0-8a5b-8379a040dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from datasets import DatasetDict, load_dataset, load_from_disk\n",
    "from datasets.combine import concatenate_datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "FRAMES_PER_VIDEO = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a3afe7-d7ff-4ebd-a4a8-6701cb46f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145d06b-b928-4661-8034-7751ecd4e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    video_id = example[\"videoID\"]\n",
    "    captions = example[\"enCap\"]\n",
    "    \n",
    "    videos_path = \"dataset/videos\"\n",
    "    video_path = os.path.join(videos_path, \"%s.mp4\" % video_id)\n",
    "    if not os.path.isfile(video_path):\n",
    "        video_path = os.path.join(videos_path, \"%s.webm\" % video_id)\n",
    "    \n",
    "    # count number of frames\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, _ = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "    video.release()\n",
    "        \n",
    "    # fixed frame sampling\n",
    "    indices = np.linspace(0, frame_count, num=FRAMES_PER_VIDEO, endpoint=False).astype(np.int64)\n",
    "    # random frame sampling\n",
    "    #indices = np.sort(np.random.uniform(low=0, high=frame_count, size=self.num_frames).astype(np.int64))\n",
    "    \n",
    "    # get frames\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_count, frame_idx = 0, 0\n",
    "    while frame_idx < len(indices):\n",
    "        if frame_count == indices[frame_idx]:\n",
    "            _, frame = video.read()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            frame_idx += 1\n",
    "        else:\n",
    "            video.grab()\n",
    "        frame_count += 1\n",
    "    video.release()\n",
    "        \n",
    "    # longest caption\n",
    "    max_len = -np.inf\n",
    "    caption = None\n",
    "    for cap in captions:\n",
    "        length = len(cap.split(\" \"))\n",
    "        if length > max_len:\n",
    "            max_len = length\n",
    "            caption = cap\n",
    "    # random caption\n",
    "    #caption = captions[random.randint(0, 9)]\n",
    "\n",
    "    labels = tokenizer(caption, padding=\"max_length\").input_ids\n",
    "    return {\"pixel_values\": frames, \"labels\": labels}\n",
    "    \n",
    "    # pixel_values = image_processor(frames, return_tensors=\"pt\").pixel_values\n",
    "    # labels = tokenizer(caption, padding=\"max_length\").input_ids\n",
    "    # return {\"pixel_values\": pixel_values[0], \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364cc2f7-5c8b-432d-9fc4-4bb8e0d9097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-dc0812067ce11954\n",
      "Found cached dataset json (/home/922201615/.cache/huggingface/datasets/json/default-dc0812067ce11954/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e536671c5b62499388fd91425676cfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['videoID', 'enCap', 'chCap'],\n",
       "        num_rows: 22895\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['videoID', 'enCap', 'chCap'],\n",
       "        num_rows: 2643\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json data\n",
    "data_files = {\"train\": \"dataset/vatex_train_captions.json\", \"validation\": \"dataset/vatex_val_captions.json\"}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "dataset\n",
    "\n",
    "# dataset[\"train\"] = dataset[\"train\"].select(np.arange(6))\n",
    "# dataset[\"validation\"] = dataset[\"validation\"].select(np.arange(3))\n",
    "\n",
    "# dataset = dataset.map(function=preprocess, remove_columns=[\"enCap\", \"chCap\"])\n",
    "# dataset.save_to_disk(\"dataset/raw_frames_16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
