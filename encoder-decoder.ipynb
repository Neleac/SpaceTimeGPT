{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afaf3f10-c8ad-47fd-b95b-9245da9bb0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:\n",
      "NVIDIA RTX A6000\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from datasets import load_from_disk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "#from transformers import VisionEncoderDecoderModel, AutoImageProcessor, AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments, default_data_collator, EarlyStoppingCallback\n",
    "\n",
    "sys.path.append(\"../transformers/src\")\n",
    "from transformers import VisionEncoderDecoderModel, AutoImageProcessor, AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments, default_data_collator, EarlyStoppingCallback\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda:0\":    \n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    print(\"GPUs:\")\n",
    "    for i in range(n_gpus):\n",
    "        print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0840708-8e75-4bf3-a615-5eecfa8760f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of the model checkpoint at facebook/timesformer-base-finetuned-k600 were not used when initializing TimesformerModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing TimesformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TimesformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.8.crossattention.c_proj.bias', 'h.4.crossattention.masked_bias', 'h.9.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.2.crossattention.bias', 'h.2.crossattention.c_proj.weight', 'h.3.ln_cross_attn.weight', 'h.1.ln_cross_attn.weight', 'h.7.ln_cross_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.7.crossattention.bias', 'h.6.crossattention.masked_bias', 'h.11.ln_cross_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.4.ln_cross_attn.weight', 'h.8.crossattention.c_attn.weight', 'h.3.crossattention.bias', 'h.3.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.1.crossattention.masked_bias', 'h.1.crossattention.q_attn.weight', 'h.0.ln_cross_attn.weight', 'h.6.crossattention.c_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.4.crossattention.c_attn.weight', 'h.1.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.bias', 'h.11.crossattention.c_proj.bias', 'h.0.crossattention.q_attn.weight', 'h.5.crossattention.bias', 'h.3.crossattention.c_proj.weight', 'h.5.crossattention.masked_bias', 'h.2.crossattention.c_proj.bias', 'h.3.crossattention.masked_bias', 'h.0.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.weight', 'h.11.crossattention.bias', 'h.9.ln_cross_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.1.crossattention.c_proj.weight', 'h.8.crossattention.masked_bias', 'h.4.crossattention.bias', 'h.8.ln_cross_attn.weight', 'h.6.ln_cross_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.bias', 'h.0.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.9.crossattention.bias', 'h.1.crossattention.c_proj.bias', 'h.9.crossattention.q_attn.weight', 'h.10.crossattention.masked_bias', 'h.3.crossattention.c_proj.bias', 'h.2.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.7.crossattention.masked_bias', 'h.0.crossattention.c_attn.weight', 'h.8.crossattention.q_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.0.crossattention.bias', 'h.2.crossattention.q_attn.weight', 'h.6.crossattention.q_attn.weight', 'h.1.crossattention.bias', 'h.10.crossattention.bias', 'h.11.crossattention.c_proj.weight', 'h.5.crossattention.c_attn.weight', 'h.2.ln_cross_attn.weight', 'h.11.crossattention.masked_bias', 'h.6.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.weight', 'h.7.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.7.crossattention.c_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# TimeSformer\n",
    "encoder = \"facebook/timesformer-base-finetuned-k600\"\n",
    "decoder = \"gpt2\"\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(decoder)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(encoder, decoder).to(device)\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.max_length = 50\n",
    "model.config.num_beams = 4\n",
    "model.config.early_stopping = True\n",
    "\n",
    "# VideoMAE\n",
    "# encoder = \"MCG-NJU/videomae-base\"\n",
    "# decoder = \"gpt2\"\n",
    "\n",
    "# image_processor = AutoImageProcessor.from_pretrained(encoder)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(decoder)\n",
    "# model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e751eba-19bf-4ea4-844e-1badd1ff9a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['videoID', 'pixel_values', 'labels'],\n",
       "        num_rows: 1016\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['videoID', 'pixel_values', 'labels'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk(\"dataset/processed/k600\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3add6c94-649d-4a67-92fb-bc02bccf3609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/922201615/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/922201615/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/922201615/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Using cuda_amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `VisionEncoderDecoderModel.forward` and have been ignored: videoID. If videoID are not expected by `VisionEncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "/home/922201615/video-caption/../transformers/src/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/922201615/anaconda3/envs/no-tfs/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running training *****\n",
      "  Num examples = 1016\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2040\n",
      "  Number of trainable parameters = 274065408\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "/home/922201615/video-caption/../transformers/src/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "/home/922201615/anaconda3/envs/no-tfs/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='115' max='2040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 115/2040 06:46 < 1:55:23, 0.28 it/s, Epoch 0.56/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"early_stopping\": true,\n",
      "  \"max_length\": 50,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     45\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     46\u001b[0m     train_output,\n\u001b[1;32m     47\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mmetrics,\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/video-caption/../transformers/src/transformers/trainer.py:1546\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1543\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1545\u001b[0m )\n\u001b[0;32m-> 1546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/video-caption/../transformers/src/transformers/trainer.py:1794\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1792\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1794\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1797\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1799\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1800\u001b[0m ):\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/video-caption/../transformers/src/transformers/trainer.py:2552\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_output[label_caption] \u001b[38;5;241m=\u001b[39m [generated_captions[i]]\n\u001b[1;32m   2551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2552\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2555\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/video-caption/../transformers/src/transformers/trainer.py:2584\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2583\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2584\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2585\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/no-tfs/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/no-tfs/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/no-tfs/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:181\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/no-tfs/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:81\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     79\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m---> 81\u001b[0m         thread\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/no-tfs/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/no-tfs/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_output, val_output = {}, {}\n",
    "output_dir = \"training/5e-5\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    fp16=True,\n",
    "    predict_with_generate=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    dataloader_num_workers=8,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=5e-5,\n",
    ")\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if label in val_output:\n",
    "            val_output[label].append(preds[i])\n",
    "        else:\n",
    "            val_output[label] = [preds[i]]\n",
    "            \n",
    "    bleu_scores = bleu.compute(predictions=preds, references=labels, smooth=True)\n",
    "    meteor_scores = meteor.compute(predictions=preds, references=labels)\n",
    "    rouge_scores = rouge.compute(predictions=preds, references=labels, rouge_types=['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    result = {}\n",
    "    result[\"bleu\"] = bleu_scores[\"bleu\"]\n",
    "    result[\"meteor\"] = meteor_scores[\"meteor\"]\n",
    "    result[\"rouge1\"] = rouge_scores[\"rouge1\"]\n",
    "    result[\"rouge2\"] = rouge_scores[\"rouge2\"]\n",
    "    result[\"rougeL\"] = rouge_scores[\"rougeL\"]\n",
    "    return result\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    train_output,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2264c1-1a1d-4bab-bca7-74c8f377b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"train_output.json\"), \"w\") as file:\n",
    "    file.write(json.dumps(train_output))\n",
    "    \n",
    "with open(os.path.join(output_dir, \"val_output.json\"), \"w\") as file:\n",
    "    file.write(json.dumps(val_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
