{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07fef3dd-ca49-42f0-8a5b-8379a040dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "import av\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c9bcad-d8b9-4e65-bdbe-b73ee4177170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fa583ef-3b66-4a9a-84cb-a2a29d33cf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/922201615/.cache/huggingface/datasets/json/default-f91978fa8d753f79/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc641532d0284fcf922f859d59f52363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/922201615/.cache/huggingface/datasets/json/default-1f02c66f53760342/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443f6ce4875f4120b7a804cc9f3e689a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['videoID', 'enCap'],\n",
       "        num_rows: 22895\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['videoID', 'enCap'],\n",
       "        num_rows: 2643\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['videoID', 'enCap'],\n",
       "        num_rows: 5297\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files={\"train\": \"dataset/captions/vatex_train_captions.json\", \"validation\": \"dataset/captions/vatex_val_captions.json\"}, num_proc=os.cpu_count()).remove_columns(\"chCap\")\n",
    "dataset[\"test\"] = load_dataset(\"json\", data_files={\"test\": \"dataset/captions/vatex_test_captions.json\"}, num_proc=os.cpu_count())[\"test\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f1ad2d-c7c1-447f-9ba5-661654b9cd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/22895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/2643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/5297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save to file videoID_captions = {\"videoID\": [captions]}\n",
    "def make_jsons(example, videoID_captions=None):\n",
    "    videoID, captions = example[\"videoID\"], example[\"enCap\"]\n",
    "    videoID_captions[videoID] = captions\n",
    "    return example\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "videoID_captions = manager.dict()\n",
    "dataset.map(make_jsons, fn_kwargs={\"videoID_captions\": videoID_captions}, num_proc=os.cpu_count())\n",
    "\n",
    "with open(\"dataset/videoID_captions.json\", \"w\") as file:\n",
    "    file.write(json.dumps(videoID_captions.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a75e3b-7892-452f-bb5a-b0a1649f2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset with features: videoID, pixel_values (8, 3, 224, 224), labels (10, 1024)\n",
    "def process(example):\n",
    "    videoID, captions = example[\"videoID\"], example[\"enCap\"]\n",
    "    \n",
    "    videos_path = \"dataset/videos\"\n",
    "    video_path = os.path.join(videos_path, \"%s.mp4\" % videoID)\n",
    "    if not os.path.isfile(video_path):\n",
    "        video_path = os.path.join(videos_path, \"%s.webm\" % videoID)\n",
    "    container = av.open(video_path)\n",
    "    \n",
    "    # discrepancy between in codec metadata, manually get frame count\n",
    "    container.seek(0)\n",
    "    frame_count = 0\n",
    "    for frame in container.decode(video=0):\n",
    "        frame_count += 1\n",
    "    \n",
    "    indices = set(np.linspace(0, frame_count, num=8, endpoint=False).astype(np.int64))\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i in indices:\n",
    "            frames.append(frame.to_ndarray(format=\"rgb24\"))   \n",
    "            \n",
    "    pixel_values = image_processor(frames).pixel_values[0]\n",
    "    labels = tokenizer(captions, padding=\"max_length\").input_ids\n",
    "    return {\"videoID\": videoID, \"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f46c4-b058-46ce-8d40-b27c63efd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(process, remove_columns=[\"enCap\"], num_proc=os.cpu_count())\n",
    "dataset.save_to_disk(\"/data1/caelen/dataset/vatex\", num_proc=os.cpu_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
